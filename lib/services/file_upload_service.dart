import 'dart:io';
import 'dart:convert';
import 'dart:typed_data';
import 'package:path/path.dart' as path;
import 'package:http_parser/http_parser.dart';
import 'package:archive/archive.dart';

/// æ–‡æœ¬æå–ç»“æœ
class TextExtractionResult {
  final String text;
  final bool success;
  final String extractionMethod;
  final int lineCount;
  final int wordCount;
  final String? error;
  final Map<String, dynamic>? metadata;

  TextExtractionResult({
    required this.text,
    required this.success,
    required this.extractionMethod,
    required this.lineCount,
    required this.wordCount,
    this.error,
    this.metadata,
  });
}

/// æ–‡æœ¬æå–å™¨æ¥å£
abstract class TextExtractor {
  String get name;
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata);
}

/// çº¯æ–‡æœ¬æå–å™¨
class PlainTextExtractor implements TextExtractor {
  @override
  String get name => 'PlainTextExtractor';

  @override
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata) async {
    try {
      final content = await file.readAsString(encoding: _getEncoding(encoding));
      final lines = content.split('\n');
      final words = content.split(RegExp(r'\s+'));
      
      return TextExtractionResult(
        text: content,
        success: true,
        extractionMethod: 'PLAIN_TEXT',
        lineCount: lines.length,
        wordCount: words.length,
        metadata: {
          'encoding': encoding,
          'avgWordsPerLine': lines.isNotEmpty ? (words.length / lines.length).toStringAsFixed(1) : '0',
        },
      );
    } catch (e) {
      return TextExtractionResult(
        text: 'çº¯æ–‡æœ¬æå–å¤±è´¥: $e',
        success: false,
        extractionMethod: 'PLAIN_TEXT_FAILED',
        lineCount: 0,
        wordCount: 0,
        error: e.toString(),
      );
    }
  }
}

/// Markdown æå–å™¨
class MarkdownExtractor implements TextExtractor {
  @override
  String get name => 'MarkdownExtractor';

  @override
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata) async {
    try {
      final content = await file.readAsString(encoding: _getEncoding(encoding));
      final lines = content.split('\n');
      final words = content.split(RegExp(r'\s+'));
      
      // åˆ†æ Markdown ç»“æ„
      final headers = content.split('\n').where((line) => line.trim().startsWith('#')).length;
      final codeBlocks = RegExp(r'```[\s\S]*?```').allMatches(content).length;
      final links = RegExp(r'\[([^\]]+)\]\(([^)]+)\)').allMatches(content).length;
      
      return TextExtractionResult(
        text: content,
        success: true,
        extractionMethod: 'MARKDOWN',
        lineCount: lines.length,
        wordCount: words.length,
        metadata: {
          'encoding': encoding,
          'headers': headers,
          'codeBlocks': codeBlocks,
          'links': links,
          'avgWordsPerLine': lines.isNotEmpty ? (words.length / lines.length).toStringAsFixed(1) : '0',
        },
      );
    } catch (e) {
      return TextExtractionResult(
        text: 'Markdown æå–å¤±è´¥: $e',
        success: false,
        extractionMethod: 'MARKDOWN_FAILED',
        lineCount: 0,
        wordCount: 0,
        error: e.toString(),
      );
    }
  }
}

/// JSON æå–å™¨
class JsonExtractor implements TextExtractor {
  @override
  String get name => 'JsonExtractor';

  @override
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata) async {
    try {
      print('ğŸ” JSON æå–å™¨å¼€å§‹å¤„ç†...');
      final content = await file.readAsString(encoding: _getEncoding(encoding));
      print('ğŸ“„ è¯»å–åˆ°å†…å®¹é•¿åº¦: ${content.length}');
      
      // å°è¯•è§£æ JSON
      dynamic jsonData;
      try {
        jsonData = jsonDecode(content);
        print('âœ… JSON è§£ææˆåŠŸ');
      } catch (jsonError) {
        print('âš ï¸ JSON è§£æå¤±è´¥ï¼Œä½œä¸ºçº¯æ–‡æœ¬å¤„ç†: $jsonError');
        // å¦‚æœ JSON è§£æå¤±è´¥ï¼Œä½œä¸ºçº¯æ–‡æœ¬å¤„ç†
        final lines = content.split('\n');
        final words = content.split(RegExp(r'\s+'));
        
        return TextExtractionResult(
          text: content,
          success: true,
          extractionMethod: 'JSON_AS_TEXT',
          lineCount: lines.length,
          wordCount: words.length,
          metadata: {
            'encoding': encoding,
            'jsonType': 'invalid_json',
            'isValidJson': false,
            'jsonError': jsonError.toString(),
          },
        );
      }
      
      final lines = content.split('\n');
      final words = content.split(RegExp(r'\s+'));
      
      // åˆ†æ JSON ç»“æ„
      final jsonType = _getJsonType(jsonData);
      final keys = jsonData is Map ? jsonData.keys.toList() : null;
      final length = jsonData is List ? jsonData.length : null;
      
      print('ğŸ“Š JSON åˆ†æç»“æœ:');
      print('  - ç±»å‹: $jsonType');
      print('  - é”®æ•°é‡: ${keys?.length ?? 0}');
      print('  - æ•°ç»„é•¿åº¦: ${length ?? 0}');
      
      return TextExtractionResult(
        text: content,
        success: true,
        extractionMethod: 'JSON',
        lineCount: lines.length,
        wordCount: words.length,
        metadata: {
          'encoding': encoding,
          'jsonType': jsonType,
          'jsonKeys': keys,
          'jsonLength': length,
          'isValidJson': true,
        },
      );
    } catch (e) {
      print('âŒ JSON æå–å™¨å¼‚å¸¸: $e');
      return TextExtractionResult(
        text: 'JSON æå–å¤±è´¥: $e',
        success: false,
        extractionMethod: 'JSON_FAILED',
        lineCount: 0,
        wordCount: 0,
        error: e.toString(),
      );
    }
  }
}

/// XML æå–å™¨
class XmlExtractor implements TextExtractor {
  @override
  String get name => 'XmlExtractor';

  @override
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata) async {
    try {
      final content = await file.readAsString(encoding: _getEncoding(encoding));
      final lines = content.split('\n');
      final words = content.split(RegExp(r'\s+'));
      
      // åˆ†æ XML ç»“æ„
      final tags = RegExp(r'<[^>]+>').allMatches(content).length;
      final elements = RegExp(r'<(\w+)').allMatches(content).map((m) => m.group(1)).toSet().length;
      
      return TextExtractionResult(
        text: content,
        success: true,
        extractionMethod: 'XML',
        lineCount: lines.length,
        wordCount: words.length,
        metadata: {
          'encoding': encoding,
          'tags': tags,
          'elements': elements,
          'avgWordsPerLine': lines.isNotEmpty ? (words.length / lines.length).toStringAsFixed(1) : '0',
        },
      );
    } catch (e) {
      return TextExtractionResult(
        text: 'XML æå–å¤±è´¥: $e',
        success: false,
        extractionMethod: 'XML_FAILED',
        lineCount: 0,
        wordCount: 0,
        error: e.toString(),
      );
    }
  }
}

/// CSV æå–å™¨
class CsvExtractor implements TextExtractor {
  @override
  String get name => 'CsvExtractor';

  @override
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata) async {
    try {
      final content = await file.readAsString(encoding: _getEncoding(encoding));
      final lines = content.split('\n');
      final words = content.split(RegExp(r'\s+'));
      
      // åˆ†æ CSV ç»“æ„
      final headers = lines.isNotEmpty ? lines.first.split(',') : [];
      final dataRows = lines.length > 1 ? lines.length - 1 : 0;
      
      return TextExtractionResult(
        text: content,
        success: true,
        extractionMethod: 'CSV',
        lineCount: lines.length,
        wordCount: words.length,
        metadata: {
          'encoding': encoding,
          'headers': headers,
          'dataRows': dataRows,
          'columnCount': headers.length,
          'avgWordsPerLine': lines.isNotEmpty ? (words.length / lines.length).toStringAsFixed(1) : '0',
        },
      );
    } catch (e) {
      return TextExtractionResult(
        text: 'CSV æå–å¤±è´¥: $e',
        success: false,
        extractionMethod: 'CSV_FAILED',
        lineCount: 0,
        wordCount: 0,
        error: e.toString(),
      );
    }
  }
}

/// DOCX æå–å™¨
class DocxExtractor implements TextExtractor {
  @override
  String get name => 'DocxExtractor';

  @override
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata) async {
    try {
      final extractedText = await _extractDocxText(file);
      final lines = extractedText.split('\n');
      final words = extractedText.split(RegExp(r'\s+'));
      
      return TextExtractionResult(
        text: extractedText,
        success: true,
        extractionMethod: 'DOCX_ZIP_PARSING',
        lineCount: lines.length,
        wordCount: words.length,
        metadata: {
          'encoding': encoding,
          'avgWordsPerLine': lines.isNotEmpty ? (words.length / lines.length).toStringAsFixed(1) : '0',
        },
      );
    } catch (e) {
      return TextExtractionResult(
        text: 'DOCX æå–å¤±è´¥: $e',
        success: false,
        extractionMethod: 'DOCX_FAILED',
        lineCount: 0,
        wordCount: 0,
        error: e.toString(),
      );
    }
  }
}

/// DOC æå–å™¨
class DocExtractor implements TextExtractor {
  @override
  String get name => 'DocExtractor';

  @override
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata) async {
    return TextExtractionResult(
      text: 'æš‚ä¸æ”¯æŒ .doc æ ¼å¼çš„æ–‡æœ¬æå–ï¼Œéœ€è¦ä¸“é—¨çš„è§£æåº“',
      success: false,
      extractionMethod: 'DOC_NOT_SUPPORTED',
      lineCount: 1,
      wordCount: 0,
      error: 'éœ€è¦ä¸“é—¨çš„ .doc è§£æåº“',
    );
  }
}

/// æå– DOCX æ–‡æ¡£æ–‡æœ¬ï¼ˆåŸºäº ZIP æ ¼å¼è§£æï¼‰
Future<String> _extractDocxText(File file) async {
  try {
    print('ğŸ” å¼€å§‹è§£æ DOCX æ–‡ä»¶ç»“æ„...');
    
    // è¯»å–æ•´ä¸ªæ–‡ä»¶
    final bytes = await file.readAsBytes();
    print('ğŸ“Š æ–‡ä»¶å­—èŠ‚æ•°: ${bytes.length}');
    
    // æ£€æŸ¥ ZIP æ–‡ä»¶å¤´
    if (bytes.length < 4 || bytes[0] != 0x50 || bytes[1] != 0x4B) {
      throw Exception('ä¸æ˜¯æœ‰æ•ˆçš„ ZIP æ–‡ä»¶æ ¼å¼');
    }
    print('âœ… ZIP æ–‡ä»¶å¤´éªŒè¯é€šè¿‡');
    
    // ä½¿ç”¨ archive åŒ…è§£æ ZIP æ–‡ä»¶
    final archive = ZipDecoder().decodeBytes(bytes);
    print('ğŸ“¦ ZIP æ–‡ä»¶è§£ææˆåŠŸï¼ŒåŒ…å« ${archive.length} ä¸ªæ–‡ä»¶');
    
    String extractedText = '';
    
    // æŸ¥æ‰¾å¹¶è§£æ word/document.xml
    for (final file in archive) {
      final fileName = file.name;
      print('ğŸ“„ æ£€æŸ¥æ–‡ä»¶: $fileName');
      
      if (fileName == 'word/document.xml') {
        print('âœ… æ‰¾åˆ°æ–‡æ¡£ä¸»ä½“æ–‡ä»¶: $fileName');
        
        try {
          // è§£å‹å¹¶è¯»å– XML å†…å®¹
          final xmlContent = utf8.decode(file.content as List<int>);
          print('ğŸ“„ XML å†…å®¹é•¿åº¦: ${xmlContent.length}');
          
          // æå–æ–‡æœ¬å†…å®¹
          extractedText = _extractTextFromXml(xmlContent);
          break;
        } catch (e) {
          print('âŒ è§£æ XML å¤±è´¥: $e');
        }
      }
    }
    
    // å¦‚æœæ²¡æœ‰æ‰¾åˆ° document.xmlï¼Œå°è¯•å…¶ä»–æ–‡ä»¶
    if (extractedText.isEmpty) {
      print('ğŸ” æœªæ‰¾åˆ° document.xmlï¼Œå°è¯•å…¶ä»–æ–‡ä»¶...');
      
      for (final file in archive) {
        final fileName = file.name;
        if (fileName.endsWith('.xml') && !fileName.contains('[')) {
          print('ğŸ“„ å°è¯•è§£æ XML æ–‡ä»¶: $fileName');
          
          try {
            final xmlContent = utf8.decode(file.content as List<int>);
            final text = _extractTextFromXml(xmlContent);
            if (text.isNotEmpty) {
              extractedText = text;
              print('âœ… ä» $fileName æå–åˆ°æ–‡æœ¬');
              break;
            }
          } catch (e) {
            print('âŒ è§£æ $fileName å¤±è´¥: $e');
          }
        }
      }
    }
    
    // æ¸…ç†å’Œæ ¼å¼åŒ–æ–‡æœ¬
    if (extractedText.isNotEmpty) {
      extractedText = extractedText
          .replaceAll(RegExp(r'\s+'), ' ')  // åˆå¹¶å¤šä¸ªç©ºæ ¼
          .replaceAll(RegExp(r'[^\w\s\u4e00-\u9fff.,!?;:()\-]'), '')  // ä¿ç•™åŸºæœ¬æ ‡ç‚¹å’Œè¿å­—ç¬¦
          .trim();
      
      print('ğŸ“Š æ¸…ç†åæ–‡æœ¬é•¿åº¦: ${extractedText.length}');
      print('ğŸ“„ æ–‡æœ¬é¢„è§ˆ: ${extractedText.substring(0, extractedText.length > 200 ? 200 : extractedText.length)}...');
      print('âœ… æ–‡æœ¬æå–å®Œæˆ');
    } else {
      extractedText = 'æ— æ³•ä» DOCX æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹';
      print('âš ï¸ æ— æ³•æå–æ–‡æœ¬å†…å®¹');
    }
    
    return extractedText;
  } catch (e) {
    print('âŒ DOCX æ–‡æœ¬æå–å¼‚å¸¸: $e');
    return 'DOCX æ–‡æœ¬æå–å¤±è´¥: $e';
  }
}

/// ä» XML å†…å®¹ä¸­æå–æ–‡æœ¬
String _extractTextFromXml(String xmlContent) {
  String extractedText = '';
  
  // æå– <w:t> æ ‡ç­¾ä¸­çš„æ–‡æœ¬
  final wTextPattern = RegExp(r'<w:t[^>]*>([^<]*)</w:t>', dotAll: true);
  final matches = wTextPattern.allMatches(xmlContent);
  
  for (final match in matches) {
    final text = match.group(1)?.trim() ?? '';
    if (text.isNotEmpty) {
      extractedText += text + ' ';
    }
  }
  
  // å¦‚æœæ²¡æœ‰æ‰¾åˆ° <w:t> æ ‡ç­¾ï¼Œå°è¯• <t> æ ‡ç­¾
  if (extractedText.isEmpty) {
    final tTextPattern = RegExp(r'<t[^>]*>([^<]*)</t>', dotAll: true);
    final tMatches = tTextPattern.allMatches(xmlContent);
    
    for (final match in tMatches) {
      final text = match.group(1)?.trim() ?? '';
      if (text.isNotEmpty) {
        extractedText += text + ' ';
      }
    }
  }
  
  return extractedText;
}

/// ä»£ç æå–å™¨
class CodeExtractor implements TextExtractor {
  @override
  String get name => 'CodeExtractor';

  @override
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata) async {
    try {
      final content = await file.readAsString(encoding: _getEncoding(encoding));
      final lines = content.split('\n');
      final words = content.split(RegExp(r'\s+'));
      
      // åˆ†æä»£ç ç»“æ„
      final nonEmptyLines = lines.where((line) => line.trim().isNotEmpty).length;
      final commentLines = lines.where((line) => 
        line.trim().startsWith('//') || 
        line.trim().startsWith('/*') || 
        line.trim().startsWith('*') ||
        line.trim().startsWith('#') ||
        line.trim().startsWith('<!--')
      ).length;
      
      return TextExtractionResult(
        text: content,
        success: true,
        extractionMethod: 'CODE',
        lineCount: lines.length,
        wordCount: words.length,
        metadata: {
          'encoding': encoding,
          'nonEmptyLines': nonEmptyLines,
          'commentLines': commentLines,
          'codeLines': nonEmptyLines - commentLines,
          'commentRatio': lines.isNotEmpty ? (commentLines / lines.length * 100).toStringAsFixed(1) : '0',
          'avgWordsPerLine': lines.isNotEmpty ? (words.length / lines.length).toStringAsFixed(1) : '0',
        },
      );
    } catch (e) {
      return TextExtractionResult(
        text: 'ä»£ç æå–å¤±è´¥: $e',
        success: false,
        extractionMethod: 'CODE_FAILED',
        lineCount: 0,
        wordCount: 0,
        error: e.toString(),
      );
    }
  }
}

/// é€šç”¨æ–‡æœ¬æå–å™¨
class GenericTextExtractor implements TextExtractor {
  @override
  String get name => 'GenericTextExtractor';

  @override
  Future<TextExtractionResult> extract(File file, String encoding, Map<String, dynamic> metadata) async {
    try {
      final content = await file.readAsString(encoding: _getEncoding(encoding));
      final lines = content.split('\n');
      final words = content.split(RegExp(r'\s+'));
      
      return TextExtractionResult(
        text: content,
        success: true,
        extractionMethod: 'GENERIC_TEXT',
        lineCount: lines.length,
        wordCount: words.length,
        metadata: {
          'encoding': encoding,
          'avgWordsPerLine': lines.isNotEmpty ? (words.length / lines.length).toStringAsFixed(1) : '0',
        },
      );
    } catch (e) {
      return TextExtractionResult(
        text: 'é€šç”¨æ–‡æœ¬æå–å¤±è´¥: $e',
        success: false,
        extractionMethod: 'GENERIC_TEXT_FAILED',
        lineCount: 0,
        wordCount: 0,
        error: e.toString(),
      );
    }
  }
}

/// è·å–ç¼–ç å¯¹è±¡
Encoding _getEncoding(String encodingName) {
  switch (encodingName.toLowerCase()) {
    case 'utf-8':
      return utf8;
    case 'utf-16le':
      return utf8; // ç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨ UTF-8
    case 'utf-16be':
      return utf8; // ç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨ UTF-8
    case 'gbk':
      return latin1; // ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä½¿ç”¨ GBK ç¼–ç 
    default:
      return utf8;
  }
}

/// è·å– JSON ç±»å‹
String _getJsonType(dynamic jsonData) {
  if (jsonData is Map) return 'object';
  if (jsonData is List) return 'array';
  if (jsonData is String) return 'string';
  if (jsonData is num) return 'number';
  if (jsonData is bool) return 'boolean';
  return 'null';
}

/// æ–‡ä»¶å¤„ç†ç»“æœ
class FileProcessResult {
  final bool success;
  final String? fileContent;
  final String? fileUrl;
  final String? error;
  final int? fileSize;
  final String? fileType;
  final String? fileName;
  final Map<String, dynamic>? metadata; // æ–°å¢ï¼šæ–‡ä»¶å…ƒæ•°æ®

  FileProcessResult({
    required this.success,
    this.fileContent,
    this.fileUrl,
    this.error,
    this.fileSize,
    this.fileType,
    this.fileName,
    this.metadata,
  });
}

/// æ–‡ä»¶ä¸Šä¼ æœåŠ¡ - ä½¿ç”¨ Flutter åŸç”Ÿèƒ½åŠ›
class FileUploadService {
  // æ”¯æŒçš„æ–‡ä»¶ç±»å‹
  static const Map<String, List<String>> supportedFileTypes = {
    'image': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.svg'],
    'document': ['.pdf', '.txt', '.doc', '.docx', '.rtf', '.md', '.json', '.xml', '.csv'],
    'code': ['.py', '.js', '.ts', '.java', '.cpp', '.c', '.h', '.html', '.css', '.php', '.rb', '.go', '.rs', '.swift', '.kt'],
    'data': ['.csv', '.json', '.xml', '.yaml', '.yml', '.sql', '.db', '.sqlite'],
    'archive': ['.zip', '.rar', '.7z', '.tar', '.gz'],
  };

  // æœ€å¤§æ–‡ä»¶å¤§å° (5MB)
  static const int maxFileSize = 5 * 1024 * 1024;

  /// å¤„ç†æ–‡ä»¶ - ä½¿ç”¨ Flutter åŸç”Ÿèƒ½åŠ›
  static Future<FileProcessResult> processFile(File file, String agentName) async {
    try {
      print('=== FileUploadService.processFile å¼€å§‹ ===');
      print('æ–‡ä»¶å: ${path.basename(file.path)}');
      print('æ–‡ä»¶æ‰©å±•å: ${path.extension(file.path)}');
      print('æ–‡ä»¶è·¯å¾„: ${file.path}');
      print('ä»£ç†åç§°: $agentName');

      // 1. åŸºç¡€æ–‡ä»¶æ£€æŸ¥
      print('ğŸ” å¼€å§‹åŸºç¡€æ–‡ä»¶æ£€æŸ¥...');
      if (!await file.exists()) {
        print('âŒ æ–‡ä»¶ä¸å­˜åœ¨: ${path.basename(file.path)}');
        return FileProcessResult(
          success: false,
          error: 'æ–‡ä»¶ä¸å­˜åœ¨: ${path.basename(file.path)}',
        );
      }
      print('âœ… æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥é€šè¿‡');

      final fileSize = await file.length();
      print('ğŸ“ æ–‡ä»¶å¤§å°: ${_formatFileSize(fileSize)} (${fileSize} bytes)');
      if (fileSize > maxFileSize) {
        print('âŒ æ–‡ä»¶è¿‡å¤§: ${_formatFileSize(fileSize)} (æœ€å¤§ ${_formatFileSize(maxFileSize)})');
        return FileProcessResult(
          success: false,
          error: 'æ–‡ä»¶è¿‡å¤§: ${_formatFileSize(fileSize)} (æœ€å¤§ ${_formatFileSize(maxFileSize)})',
        );
      }
      print('âœ… æ–‡ä»¶å¤§å°æ£€æŸ¥é€šè¿‡');

      final extension = path.extension(file.path).toLowerCase();
      print('ğŸ“‹ æ–‡ä»¶æ‰©å±•å: $extension');
      if (!_isFileTypeSupported(extension)) {
        print('âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: $extension');
        return FileProcessResult(
          success: false,
          error: 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: $extension',
        );
      }
      print('âœ… æ–‡ä»¶ç±»å‹æ£€æŸ¥é€šè¿‡');

      // 2. æå–æ–‡ä»¶å…ƒæ•°æ®
      print('ğŸ” å¼€å§‹æå–æ–‡ä»¶å…ƒæ•°æ®...');
      final metadata = await _extractFileMetadata(file);
      print('ğŸ“Š æ–‡ä»¶å…ƒæ•°æ®æå–å®Œæˆ:');
      _printMetadataDetails(metadata);

      // 3. æ ¹æ®æ–‡ä»¶ç±»å‹æ™ºèƒ½å¤„ç†
      print('ğŸ”§ å¼€å§‹æ ¹æ®æ–‡ä»¶ç±»å‹æ™ºèƒ½å¤„ç†...');
      final result = await _processFileByType(file, extension, metadata);
      
      print('ğŸ“‹ æ–‡ä»¶å¤„ç†ç»“æœ:');
      print('- æˆåŠŸ: ${result.success}');
      print('- é”™è¯¯: ${result.error}');
      print('- å†…å®¹é•¿åº¦: ${result.fileContent?.length ?? 0}');
      print('- å…ƒæ•°æ®: ${result.metadata}');

      return result;

    } catch (e) {
      print('âŒ æ–‡ä»¶å¤„ç†å¼‚å¸¸: $e');
      return FileProcessResult(
        success: false,
        error: 'æ–‡ä»¶å¤„ç†å¼‚å¸¸: $e',
      );
    }
  }

  /// æå–æ–‡ä»¶å…ƒæ•°æ®
  static Future<Map<String, dynamic>> _extractFileMetadata(File file) async {
    final stat = await file.stat();
    final extension = path.extension(file.path).toLowerCase();
    
    return {
      'fileName': path.basename(file.path),
      'filePath': file.path,
      'fileSize': stat.size,
      'fileSizeFormatted': _formatFileSize(stat.size),
      'fileExtension': extension,
      'mimeType': _getMimeType(extension),
      'lastModified': stat.modified.toIso8601String(),
      'created': stat.changed.toIso8601String(),
      'fileType': _getFileTypeCategory(extension),
      'isReadable': await file.exists(),
    };
  }

  /// æ ¹æ®æ–‡ä»¶ç±»å‹æ™ºèƒ½å¤„ç†
  static Future<FileProcessResult> _processFileByType(
    File file, 
    String extension, 
    Map<String, dynamic> metadata
  ) async {
    
    switch (_getFileTypeCategory(extension)) {
      case 'image':
        return await _processImageFile(file, metadata);
      case 'document':
        return await _processDocumentFile(file, metadata);
      case 'code':
        return await _processCodeFile(file, metadata);
      case 'data':
        return await _processDataFile(file, metadata);
      case 'archive':
        return await _processArchiveFile(file, metadata);
      default:
        return await _processGenericFile(file, metadata);
    }
  }

  /// é€šç”¨æ–‡æœ¬æå–å™¨
  static Future<TextExtractionResult> _extractTextFromFile(File file, Map<String, dynamic> metadata) async {
    final extension = metadata['fileExtension'] as String;
    final fileName = metadata['fileName'] as String;
    
    print('ğŸ“„ å¼€å§‹é€šç”¨æ–‡æœ¬æå–...');
    print('ğŸ“ æ–‡ä»¶: $fileName');
    print('ğŸ“‹ æ‰©å±•å: $extension');
    
    try {
      // 1. æ£€æµ‹æ–‡ä»¶ç¼–ç 
      final encoding = await _detectFileEncoding(file);
      print('ğŸ” æ£€æµ‹åˆ°æ–‡ä»¶ç¼–ç : $encoding');
      
      // 2. æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©æå–ç­–ç•¥
      final extractor = _getTextExtractor(extension);
      print('ğŸ”§ ä½¿ç”¨æå–å™¨: ${extractor.name}');
      
      // 3. æ‰§è¡Œæ–‡æœ¬æå–
      final result = await extractor.extract(file, encoding, metadata);
      
      print('âœ… æ–‡æœ¬æå–å®Œæˆ');
      print('ğŸ“Š æå–ç»Ÿè®¡:');
      print('  - æ–‡æœ¬é•¿åº¦: ${result.text.length} å­—ç¬¦');
      print('  - è¡Œæ•°: ${result.lineCount}');
      print('  - å•è¯æ•°: ${result.wordCount}');
      print('  - æå–æ–¹æ³•: ${result.extractionMethod}');
      
      return result;
    } catch (e) {
      print('âŒ æ–‡æœ¬æå–å¤±è´¥: $e');
      return TextExtractionResult(
        text: 'æ–‡æœ¬æå–å¤±è´¥: $e',
        success: false,
        extractionMethod: 'FAILED',
        lineCount: 0,
        wordCount: 0,
        error: e.toString(),
      );
    }
  }

  /// æ£€æµ‹æ–‡ä»¶ç¼–ç 
  static Future<String> _detectFileEncoding(File file) async {
    try {
      // è¯»å–æ–‡ä»¶å¤´éƒ¨æ¥æ£€æµ‹ç¼–ç 
      final bytes = await file.openRead(0, 1024).first;
      
      // æ£€æŸ¥ BOM (Byte Order Mark)
      if (bytes.length >= 3 && bytes[0] == 0xEF && bytes[1] == 0xBB && bytes[2] == 0xBF) {
        return 'utf-8';
      } else if (bytes.length >= 2 && bytes[0] == 0xFF && bytes[1] == 0xFE) {
        return 'utf-16le';
      } else if (bytes.length >= 2 && bytes[0] == 0xFE && bytes[1] == 0xFF) {
        return 'utf-16be';
      }
      
      // å°è¯•æ£€æµ‹ UTF-8
      try {
        final content = String.fromCharCodes(bytes);
        if (content.contains('')) {
          // åŒ…å«æ›¿æ¢å­—ç¬¦ï¼Œå¯èƒ½ä¸æ˜¯ UTF-8
          return 'gbk'; // å‡è®¾æ˜¯ GBK
        }
        return 'utf-8';
      } catch (e) {
        return 'gbk'; // é»˜è®¤ä½¿ç”¨ GBK
      }
    } catch (e) {
      return 'utf-8'; // é»˜è®¤ä½¿ç”¨ UTF-8
    }
  }

  /// è·å–æ–‡æœ¬æå–å™¨
  static TextExtractor _getTextExtractor(String extension) {
    switch (extension.toLowerCase()) {
      case '.txt':
        return PlainTextExtractor();
      case '.md':
        return MarkdownExtractor();
      case '.json':
        return JsonExtractor();
      case '.xml':
        return XmlExtractor();
      case '.csv':
        return CsvExtractor();
      case '.docx':
        return DocxExtractor();
      case '.doc':
        return DocExtractor();
      case '.py':
      case '.js':
      case '.ts':
      case '.java':
      case '.cpp':
      case '.c':
      case '.h':
      case '.html':
      case '.css':
      case '.php':
      case '.rb':
      case '.go':
      case '.rs':
      case '.swift':
      case '.kt':
        return CodeExtractor();
      default:
        return GenericTextExtractor();
    }
  }

  /// å¤„ç†å›¾ç‰‡æ–‡ä»¶
  static Future<FileProcessResult> _processImageFile(File file, Map<String, dynamic> metadata) async {
    try {
      print('ğŸ–¼ï¸ å¼€å§‹å¤„ç†å›¾ç‰‡æ–‡ä»¶...');
      print('ğŸ“ å›¾ç‰‡æ–‡ä»¶: ${metadata['fileName']}');
      print('ğŸ¯ MIME ç±»å‹: ${metadata['mimeType']}');
      
      // è¯»å–å›¾ç‰‡æ–‡ä»¶ä¸º base64
      print('ğŸ“– å¼€å§‹è¯»å–å›¾ç‰‡æ–‡ä»¶å­—èŠ‚...');
      final bytes = await file.readAsBytes();
      print('ğŸ“Š å›¾ç‰‡å­—èŠ‚æ•°: ${bytes.length}');
      
      print('ğŸ”„ å¼€å§‹è½¬æ¢ä¸º Base64...');
      final base64String = base64Encode(bytes);
      print('ğŸ“ Base64 é•¿åº¦: ${base64String.length}');
      
      final mimeType = metadata['mimeType'] as String;
      print('ğŸ¯ æœ€ç»ˆ MIME ç±»å‹: $mimeType');
      
      // å°è¯•è·å–å›¾ç‰‡å°ºå¯¸
      print('ğŸ“ å°è¯•è·å–å›¾ç‰‡å°ºå¯¸...');
      final dimensions = await _getImageDimensions(file);
      if (dimensions != null) {
        print('ğŸ“ å›¾ç‰‡å°ºå¯¸: ${dimensions['width']} x ${dimensions['height']}');
      } else {
        print('âš ï¸ æ— æ³•è·å–å›¾ç‰‡å°ºå¯¸');
      }
      
      final result = FileProcessResult(
        success: true,
        fileContent: 'data:$mimeType;base64,$base64String',
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'image',
          'base64Length': base64String.length,
          'dimensions': dimensions,
        },
      );
      
      print('âœ… å›¾ç‰‡æ–‡ä»¶å¤„ç†å®Œæˆ');
      print('ğŸ“Š å¤„ç†ç»“æœå…ƒæ•°æ®:');
      _printProcessResultMetadata(result.metadata);
      
      return result;
    } catch (e) {
      print('âŒ å›¾ç‰‡å¤„ç†å¤±è´¥: $e');
      return FileProcessResult(
        success: false,
        error: 'å›¾ç‰‡å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// å¤„ç†æ–‡æ¡£æ–‡ä»¶
  static Future<FileProcessResult> _processDocumentFile(File file, Map<String, dynamic> metadata) async {
    try {
      print('ğŸ“„ å¼€å§‹å¤„ç†æ–‡æ¡£æ–‡ä»¶...');
      print('ğŸ“ æ–‡æ¡£æ–‡ä»¶: ${metadata['fileName']}');
      print('ğŸ“‹ æ–‡ä»¶æ‰©å±•å: ${metadata['fileExtension']}');
      
      final extension = metadata['fileExtension'] as String;
      
      switch (extension) {
        case '.txt':
        case '.md':
        case '.json':
        case '.xml':
        case '.csv':
        case '.doc':
        case '.docx':
          print('ğŸ“ æ£€æµ‹åˆ°æ–‡æœ¬æ–‡ä»¶ï¼Œä½¿ç”¨é€šç”¨æ–‡æœ¬æå–å™¨...');
          // ä½¿ç”¨é€šç”¨æ–‡æœ¬æå–å™¨
          final extractionResult = await _extractTextFromFile(file, metadata);
          
          // å³ä½¿æå–å¤±è´¥ï¼Œä¹Ÿè¦è¿”å›å†…å®¹ï¼ˆå¯èƒ½æ˜¯é”™è¯¯ä¿¡æ¯ï¼Œä½†è‡³å°‘ä¸æ˜¯ç©ºçš„ï¼‰
          final result = FileProcessResult(
            success: true, // æ€»æ˜¯è¿”å›æˆåŠŸï¼Œè®©å†…å®¹ä¼ é€’ç»™ LLM
            fileContent: extractionResult.text,
            fileSize: metadata['fileSize'] as int,
            fileType: metadata['fileType'] as String,
            fileName: metadata['fileName'] as String,
            metadata: {
              ...metadata,
              'contentType': 'text',
              'lineCount': extractionResult.lineCount,
              'wordCount': extractionResult.wordCount,
              'extractionMethod': extractionResult.extractionMethod,
              'extractionMetadata': extractionResult.metadata,
              'extractionSuccess': extractionResult.success,
              'extractionError': extractionResult.error,
            },
          );
          
          print('âœ… æ–‡æ¡£æ–‡ä»¶å¤„ç†å®Œæˆ');
          print('ğŸ“Š å¤„ç†ç»“æœå…ƒæ•°æ®:');
          _printProcessResultMetadata(result.metadata);
          
          return result;
          
        case '.pdf':
          print('ğŸ“„ æ£€æµ‹åˆ° PDF æ–‡ä»¶...');
          // PDF æ–‡ä»¶æå–æ–‡æœ¬ä¿¡æ¯
          return await _processPdfFile(file, metadata);
          
        default:
          print('ğŸ“„ æœªçŸ¥æ–‡æ¡£ç±»å‹ï¼Œä½¿ç”¨é€šç”¨å¤„ç†...');
          return await _processGenericFile(file, metadata);
      }
    } catch (e) {
      print('âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: $e');
      return FileProcessResult(
        success: false,
        error: 'æ–‡æ¡£å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// å¤„ç†ä»£ç æ–‡ä»¶
  static Future<FileProcessResult> _processCodeFile(File file, Map<String, dynamic> metadata) async {
    try {
      print('ğŸ’» å¼€å§‹å¤„ç†ä»£ç æ–‡ä»¶...');
      print('ğŸ“ ä»£ç æ–‡ä»¶: ${metadata['fileName']}');
      print('ğŸ“‹ æ–‡ä»¶æ‰©å±•å: ${metadata['fileExtension']}');
      
      // ä½¿ç”¨é€šç”¨æ–‡æœ¬æå–å™¨
      final extractionResult = await _extractTextFromFile(file, metadata);
      
      final result = FileProcessResult(
        success: true, // æ€»æ˜¯è¿”å›æˆåŠŸï¼Œè®©å†…å®¹ä¼ é€’ç»™ LLM
        fileContent: extractionResult.text,
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'code',
          'language': _getProgrammingLanguage(metadata['fileExtension'] as String),
          'lineCount': extractionResult.lineCount,
          'wordCount': extractionResult.wordCount,
          'extractionMethod': extractionResult.extractionMethod,
          'extractionMetadata': extractionResult.metadata,
          'extractionSuccess': extractionResult.success,
          'extractionError': extractionResult.error,
        },
      );
      
      print('âœ… ä»£ç æ–‡ä»¶å¤„ç†å®Œæˆ');
      print('ğŸ“Š å¤„ç†ç»“æœå…ƒæ•°æ®:');
      _printProcessResultMetadata(result.metadata);
      
      return result;
    } catch (e) {
      print('âŒ ä»£ç æ–‡ä»¶å¤„ç†å¤±è´¥: $e');
      return FileProcessResult(
        success: false,
        error: 'ä»£ç æ–‡ä»¶å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// å¤„ç†æ•°æ®æ–‡ä»¶
  static Future<FileProcessResult> _processDataFile(File file, Map<String, dynamic> metadata) async {
    try {
      print('ğŸ“Š å¼€å§‹å¤„ç†æ•°æ®æ–‡ä»¶...');
      print('ğŸ“ æ•°æ®æ–‡ä»¶: ${metadata['fileName']}');
      print('ğŸ“‹ æ–‡ä»¶æ‰©å±•å: ${metadata['fileExtension']}');
      
      final extension = metadata['fileExtension'] as String;
      
      switch (extension) {
        case '.csv':
        case '.json':
        case '.xml':
          print('ğŸ“Š æ£€æµ‹åˆ°ç»“æ„åŒ–æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨é€šç”¨æ–‡æœ¬æå–å™¨...');
          // ä½¿ç”¨é€šç”¨æ–‡æœ¬æå–å™¨
          final extractionResult = await _extractTextFromFile(file, metadata);
          
          final result = FileProcessResult(
            success: true, // æ€»æ˜¯è¿”å›æˆåŠŸï¼Œè®©å†…å®¹ä¼ é€’ç»™ LLM
            fileContent: extractionResult.text,
            fileSize: metadata['fileSize'] as int,
            fileType: metadata['fileType'] as String,
            fileName: metadata['fileName'] as String,
            metadata: {
              ...metadata,
              'contentType': 'data',
              'lineCount': extractionResult.lineCount,
              'wordCount': extractionResult.wordCount,
              'extractionMethod': extractionResult.extractionMethod,
              'extractionMetadata': extractionResult.metadata,
              'extractionSuccess': extractionResult.success,
              'extractionError': extractionResult.error,
            },
          );
          
          print('âœ… æ•°æ®æ–‡ä»¶å¤„ç†å®Œæˆ');
          print('ğŸ“Š å¤„ç†ç»“æœå…ƒæ•°æ®:');
          _printProcessResultMetadata(result.metadata);
          
          return result;
          
        default:
          print('ğŸ“Š æœªçŸ¥æ•°æ®æ–‡ä»¶ç±»å‹ï¼Œä½¿ç”¨é€šç”¨å¤„ç†...');
          return await _processGenericFile(file, metadata);
      }
    } catch (e) {
      print('âŒ æ•°æ®æ–‡ä»¶å¤„ç†å¤±è´¥: $e');
      return FileProcessResult(
        success: false,
        error: 'æ•°æ®æ–‡ä»¶å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// å¤„ç†å‹ç¼©æ–‡ä»¶
  static Future<FileProcessResult> _processArchiveFile(File file, Map<String, dynamic> metadata) async {
    try {
      // å¯¹äºå‹ç¼©æ–‡ä»¶ï¼Œæˆ‘ä»¬æä¾›æ–‡ä»¶ä¿¡æ¯è€Œä¸æ˜¯è§£å‹å†…å®¹
      return FileProcessResult(
        success: true,
        fileContent: 'å‹ç¼©æ–‡ä»¶: ${metadata['fileName']} (${metadata['fileSizeFormatted']})',
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'archive',
          'note': 'å‹ç¼©æ–‡ä»¶å†…å®¹éœ€è¦è§£å‹åæ‰èƒ½æŸ¥çœ‹',
        },
      );
    } catch (e) {
      return FileProcessResult(
        success: false,
        error: 'å‹ç¼©æ–‡ä»¶å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// å¤„ç†é€šç”¨æ–‡ä»¶
  static Future<FileProcessResult> _processGenericFile(File file, Map<String, dynamic> metadata) async {
    try {
      // å°è¯•ä½œä¸ºæ–‡æœ¬æ–‡ä»¶è¯»å–
      final content = await file.readAsString(encoding: utf8);
      return FileProcessResult(
        success: true,
        fileContent: content,
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'text',
          'lineCount': content.split('\n').length,
        },
      );
    } catch (e) {
      // å¦‚æœæ— æ³•ä½œä¸ºæ–‡æœ¬è¯»å–ï¼Œæä¾›æ–‡ä»¶ä¿¡æ¯
      return FileProcessResult(
        success: true,
        fileContent: 'äºŒè¿›åˆ¶æ–‡ä»¶: ${metadata['fileName']} (${metadata['fileSizeFormatted']})',
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'binary',
          'note': 'æ— æ³•è¯»å–äºŒè¿›åˆ¶æ–‡ä»¶å†…å®¹',
        },
      );
    }
  }

  /// å¤„ç† CSV æ–‡ä»¶
  static Future<FileProcessResult> _processCsvFile(File file, Map<String, dynamic> metadata) async {
    try {
      final content = await file.readAsString(encoding: utf8);
      final lines = content.split('\n');
      final headers = lines.isNotEmpty ? lines.first.split(',') : [];
      
      return FileProcessResult(
        success: true,
        fileContent: content,
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'csv',
          'lineCount': lines.length,
          'columnCount': headers.length,
          'headers': headers,
          'dataPreview': lines.length > 1 ? lines.take(5).toList() : [],
        },
      );
    } catch (e) {
      return FileProcessResult(
        success: false,
        error: 'CSV æ–‡ä»¶å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// å¤„ç† JSON æ–‡ä»¶
  static Future<FileProcessResult> _processJsonFile(File file, Map<String, dynamic> metadata) async {
    try {
      final content = await file.readAsString(encoding: utf8);
      final jsonData = jsonDecode(content);
      
      return FileProcessResult(
        success: true,
        fileContent: content,
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'json',
          'jsonType': _getJsonType(jsonData),
          'jsonKeys': jsonData is Map ? jsonData.keys.toList() : null,
          'jsonLength': jsonData is List ? jsonData.length : null,
        },
      );
    } catch (e) {
      return FileProcessResult(
        success: false,
        error: 'JSON æ–‡ä»¶å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// å¤„ç† XML æ–‡ä»¶
  static Future<FileProcessResult> _processXmlFile(File file, Map<String, dynamic> metadata) async {
    try {
      final content = await file.readAsString(encoding: utf8);
      
      return FileProcessResult(
        success: true,
        fileContent: content,
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'xml',
          'lineCount': content.split('\n').length,
        },
      );
    } catch (e) {
      return FileProcessResult(
        success: false,
        error: 'XML æ–‡ä»¶å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// å¤„ç† PDF æ–‡ä»¶ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
  static Future<FileProcessResult> _processPdfFile(File file, Map<String, dynamic> metadata) async {
    try {
      // ç®€åŒ–å¤„ç†ï¼šæä¾›æ–‡ä»¶ä¿¡æ¯
      return FileProcessResult(
        success: true,
        fileContent: 'PDF æ–‡ä»¶: ${metadata['fileName']} (${metadata['fileSizeFormatted']})',
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'pdf',
          'note': 'PDF å†…å®¹éœ€è¦ä¸“é—¨çš„è§£æåº“',
        },
      );
    } catch (e) {
      return FileProcessResult(
        success: false,
        error: 'PDF æ–‡ä»¶å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// å¤„ç† Word æ–‡ä»¶ï¼ˆæ”¯æŒæ–‡æœ¬æå–ï¼‰
  static Future<FileProcessResult> _processWordFile(File file, Map<String, dynamic> metadata) async {
    try {
      print('ğŸ“„ å¼€å§‹å¤„ç† Word æ–‡æ¡£...');
      print('ğŸ“ Word æ–‡ä»¶: ${metadata['fileName']}');
      print('ğŸ“ æ–‡ä»¶å¤§å°: ${metadata['fileSizeFormatted']}');
      print('ğŸ“‹ æ–‡ä»¶æ‰©å±•å: ${metadata['fileExtension']}');
      
      // å°è¯•è¯»å–æ–‡ä»¶å¤´éƒ¨ä¿¡æ¯
      print('ğŸ” å°è¯•è¯»å–æ–‡ä»¶å¤´éƒ¨ä¿¡æ¯...');
      final bytes = await file.openRead(0, 100).first;
      final header = String.fromCharCodes(bytes);
      print('ğŸ“Š æ–‡ä»¶å¤´éƒ¨ä¿¡æ¯: ${header.substring(0, header.length > 50 ? 50 : header.length)}...');
      
      // æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ Word æ–‡æ¡£
      final isDocx = metadata['fileName'].toLowerCase().endsWith('.docx');
      final isDoc = metadata['fileName'].toLowerCase().endsWith('.doc');
      
      print('ğŸ” Word æ–‡æ¡£ç±»å‹æ£€æµ‹:');
      print('  - æ˜¯å¦ä¸º .docx: $isDocx');
      print('  - æ˜¯å¦ä¸º .doc: $isDoc');
      
      String extractedText = '';
      bool canExtractText = false;
      Map<String, dynamic> extractionInfo = {};
      
      if (isDocx) {
        print('ğŸ” å°è¯•æå– DOCX æ–‡æ¡£æ–‡æœ¬...');
        try {
          extractedText = await _extractDocxText(file);
          canExtractText = extractedText.isNotEmpty;
          extractionInfo = {
            'extractionMethod': 'DOCX_ZIP_PARSING',
            'textLength': extractedText.length,
            'paragraphCount': extractedText.split('\n\n').length,
            'wordCount': extractedText.split(RegExp(r'\s+')).length,
          };
          print('âœ… DOCX æ–‡æœ¬æå–æˆåŠŸ');
          print('ğŸ“Š æå–ç»Ÿè®¡:');
          print('  - æ–‡æœ¬é•¿åº¦: ${extractedText.length} å­—ç¬¦');
          print('  - æ®µè½æ•°: ${extractionInfo['paragraphCount']}');
          print('  - å•è¯æ•°: ${extractionInfo['wordCount']}');
        } catch (e) {
          print('âš ï¸ DOCX æ–‡æœ¬æå–å¤±è´¥: $e');
          extractedText = 'æ— æ³•æå– DOCX æ–‡æ¡£æ–‡æœ¬å†…å®¹';
          extractionInfo = {
            'extractionMethod': 'FAILED',
            'error': e.toString(),
          };
        }
      } else if (isDoc) {
        print('âš ï¸ .doc æ ¼å¼æš‚ä¸æ”¯æŒæ–‡æœ¬æå–');
        extractedText = 'æš‚ä¸æ”¯æŒ .doc æ ¼å¼çš„æ–‡æœ¬æå–';
        extractionInfo = {
          'extractionMethod': 'NOT_SUPPORTED',
          'note': 'éœ€è¦ä¸“é—¨çš„ .doc è§£æåº“',
        };
      } else {
        print('âš ï¸ æœªçŸ¥ Word æ–‡æ¡£æ ¼å¼');
        extractedText = 'æœªçŸ¥ Word æ–‡æ¡£æ ¼å¼';
        extractionInfo = {
          'extractionMethod': 'UNKNOWN_FORMAT',
        };
      }
      
      // æ„å»ºæœ€ç»ˆå†…å®¹
      final content = canExtractText 
          ? extractedText 
          : 'Word æ–‡æ¡£: ${metadata['fileName']} (${metadata['fileSizeFormatted']})\n\n$extractedText';
      
      final result = FileProcessResult(
        success: true,
        fileContent: content,
        fileSize: metadata['fileSize'] as int,
        fileType: metadata['fileType'] as String,
        fileName: metadata['fileName'] as String,
        metadata: {
          ...metadata,
          'contentType': 'word',
          'wordFormat': isDocx ? 'DOCX' : isDoc ? 'DOC' : 'Unknown',
          'canExtractText': canExtractText,
          'extractionInfo': extractionInfo,
          'fileHeader': header.substring(0, header.length > 100 ? 100 : header.length),
          'suggestedLibraries': canExtractText ? [] : ['docx', 'msword', 'flutter_docx'],
        },
      );
      
      print('âœ… Word æ–‡æ¡£å¤„ç†å®Œæˆ');
      print('ğŸ“Š å¤„ç†ç»“æœå…ƒæ•°æ®:');
      _printProcessResultMetadata(result.metadata);
      
      return result;
    } catch (e) {
      print('âŒ Word æ–‡ä»¶å¤„ç†å¤±è´¥: $e');
      return FileProcessResult(
        success: false,
        error: 'Word æ–‡ä»¶å¤„ç†å¤±è´¥: $e',
        metadata: metadata,
      );
    }
  }

  /// æå– DOCX æ–‡æ¡£æ–‡æœ¬ï¼ˆåŸºäº ZIP æ ¼å¼è§£æï¼‰
  static Future<String> _extractDocxText(File file) async {
    try {
      print('ğŸ” å¼€å§‹è§£æ DOCX æ–‡ä»¶ç»“æ„...');
      
      // è¯»å–æ•´ä¸ªæ–‡ä»¶
      final bytes = await file.readAsBytes();
      print('ğŸ“Š æ–‡ä»¶å­—èŠ‚æ•°: ${bytes.length}');
      
      // æ£€æŸ¥ ZIP æ–‡ä»¶å¤´
      if (bytes.length < 4 || bytes[0] != 0x50 || bytes[1] != 0x4B) {
        throw Exception('ä¸æ˜¯æœ‰æ•ˆçš„ ZIP æ–‡ä»¶æ ¼å¼');
      }
      print('âœ… ZIP æ–‡ä»¶å¤´éªŒè¯é€šè¿‡');
      
      // ç®€å•çš„æ–‡æœ¬æå–ï¼ˆåŸºäºå¸¸è§çš„ DOCX ç»“æ„ï¼‰
      String extractedText = '';
      
      // å°è¯•æŸ¥æ‰¾æ–‡æ¡£å†…å®¹
      final content = String.fromCharCodes(bytes);
      
      // æŸ¥æ‰¾å¯èƒ½çš„æ–‡æœ¬å†…å®¹ï¼ˆç®€åŒ–æ–¹æ³•ï¼‰
      final textPatterns = [
        RegExp(r'<w:t[^>]*>(.*?)</w:t>', dotAll: true),  // Word æ–‡æœ¬æ ‡ç­¾
        RegExp(r'<t[^>]*>(.*?)</t>', dotAll: true),      // è¡¨æ ¼æ–‡æœ¬æ ‡ç­¾
        RegExp(r'<p[^>]*>(.*?)</p>', dotAll: true),      // æ®µè½æ ‡ç­¾
      ];
      
      for (final pattern in textPatterns) {
        final matches = pattern.allMatches(content);
        if (matches.isNotEmpty) {
          print('ğŸ” æ‰¾åˆ° ${matches.length} ä¸ªæ–‡æœ¬åŒ¹é…');
          for (final match in matches) {
            final text = match.group(1)?.trim() ?? '';
            if (text.isNotEmpty && text.length > 1) {
              extractedText += text + ' ';
            }
          }
        }
      }
      
      // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æ„åŒ–æ–‡æœ¬ï¼Œå°è¯•æå–å¯è¯»æ–‡æœ¬
      if (extractedText.isEmpty) {
        print('ğŸ” å°è¯•æå–å¯è¯»æ–‡æœ¬...');
        final readablePattern = RegExp(r'[a-zA-Z\u4e00-\u9fff]{2,}', dotAll: true);
        final matches = readablePattern.allMatches(content);
        
        final words = <String>[];
        for (final match in matches) {
          final word = match.group(0)?.trim() ?? '';
          if (word.isNotEmpty && word.length > 1) {
            words.add(word);
          }
        }
        
        if (words.isNotEmpty) {
          extractedText = words.join(' ');
          print('ğŸ“Š æå–åˆ° ${words.length} ä¸ªå¯è¯»å•è¯');
        }
      }
      
      // æ¸…ç†å’Œæ ¼å¼åŒ–æ–‡æœ¬
      if (extractedText.isNotEmpty) {
        extractedText = extractedText
            .replaceAll(RegExp(r'\s+'), ' ')  // åˆå¹¶å¤šä¸ªç©ºæ ¼
            .replaceAll(RegExp(r'[^\w\s\u4e00-\u9fff.,!?;:()]'), '')  // ä¿ç•™åŸºæœ¬æ ‡ç‚¹
            .trim();
        
        print('ğŸ“Š æ¸…ç†åæ–‡æœ¬é•¿åº¦: ${extractedText.length}');
        print('ğŸ“„ æ–‡æœ¬é¢„è§ˆ: ${extractedText.substring(0, extractedText.length > 200 ? 200 : extractedText.length)}...');
      } else {
        extractedText = 'æ— æ³•ä» DOCX æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹';
        print('âš ï¸ æ— æ³•æå–æ–‡æœ¬å†…å®¹');
      }
      
      return extractedText;
    } catch (e) {
      print('âŒ DOCX æ–‡æœ¬æå–å¼‚å¸¸: $e');
      return 'DOCX æ–‡æœ¬æå–å¤±è´¥: $e';
    }
  }

  /// åˆ†æä»£ç æ–‡ä»¶
  static Map<String, dynamic> _analyzeCodeFile(String content, String extension) {
    final lines = content.split('\n');
    final nonEmptyLines = lines.where((line) => line.trim().isNotEmpty).length;
    final commentLines = lines.where((line) => line.trim().startsWith('//') || line.trim().startsWith('/*') || line.trim().startsWith('*')).length;
    
    return {
      'totalLines': lines.length,
      'nonEmptyLines': nonEmptyLines,
      'commentLines': commentLines,
      'codeLines': nonEmptyLines - commentLines,
      'commentRatio': lines.isNotEmpty ? (commentLines / lines.length * 100).toStringAsFixed(1) : '0',
    };
  }

  /// è·å–ç¼–ç¨‹è¯­è¨€
  static String _getProgrammingLanguage(String extension) {
    final languageMap = {
      '.py': 'Python',
      '.js': 'JavaScript',
      '.ts': 'TypeScript',
      '.java': 'Java',
      '.cpp': 'C++',
      '.c': 'C',
      '.h': 'C/C++ Header',
      '.html': 'HTML',
      '.css': 'CSS',
      '.php': 'PHP',
      '.rb': 'Ruby',
      '.go': 'Go',
      '.rs': 'Rust',
      '.swift': 'Swift',
      '.kt': 'Kotlin',
    };
    
    return languageMap[extension] ?? 'Unknown';
  }

  /// è·å– JSON ç±»å‹
  static String _getJsonType(dynamic jsonData) {
    if (jsonData is Map) return 'object';
    if (jsonData is List) return 'array';
    if (jsonData is String) return 'string';
    if (jsonData is num) return 'number';
    if (jsonData is bool) return 'boolean';
    return 'null';
  }

  /// è·å–å›¾ç‰‡å°ºå¯¸ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
  static Future<Map<String, dynamic>?> _getImageDimensions(File file) async {
    try {
      // è¿™é‡Œå¯ä»¥é›†æˆå›¾ç‰‡å¤„ç†åº“æ¥è·å–å®é™…å°ºå¯¸
      // ç›®å‰è¿”å› null è¡¨ç¤ºæ— æ³•è·å–
      return null;
    } catch (e) {
      return null;
    }
  }

  /// æ£€æŸ¥æ–‡ä»¶ç±»å‹æ˜¯å¦æ”¯æŒ
  static bool _isFileTypeSupported(String extension) {
    return supportedFileTypes.values.any((types) => types.contains(extension));
  }

  /// æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦æœ‰æ•ˆ
  static bool _isFileSizeValid(int size) {
    return size <= maxFileSize;
  }

  /// è·å– MIME ç±»å‹
  static String _getMimeType(String extension) {
    final mimeTypeMap = {
      '.jpg': 'image/jpeg',
      '.jpeg': 'image/jpeg',
      '.png': 'image/png',
      '.gif': 'image/gif',
      '.bmp': 'image/bmp',
      '.webp': 'image/webp',
      '.svg': 'image/svg+xml',
      '.pdf': 'application/pdf',
      '.txt': 'text/plain',
      '.json': 'application/json',
      '.xml': 'application/xml',
      '.csv': 'text/csv',
      '.md': 'text/markdown',
      '.py': 'text/x-python',
      '.js': 'application/javascript',
      '.ts': 'application/typescript',
      '.java': 'text/x-java-source',
      '.cpp': 'text/x-c++src',
      '.c': 'text/x-csrc',
      '.html': 'text/html',
      '.css': 'text/css',
      '.zip': 'application/zip',
    };
    
    return mimeTypeMap[extension] ?? 'application/octet-stream';
  }

  /// è·å–æ–‡ä»¶ç±»å‹åˆ†ç±»
  static String _getFileTypeCategory(String extension) {
    for (final entry in supportedFileTypes.entries) {
      if (entry.value.contains(extension)) {
        return entry.key;
      }
    }
    return 'unknown';
  }

  /// æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
  static String _formatFileSize(int bytes) {
    if (bytes < 1024) return '$bytes B';
    if (bytes < 1024 * 1024) return '${(bytes / 1024).toStringAsFixed(1)} KB';
    if (bytes < 1024 * 1024 * 1024) return '${(bytes / (1024 * 1024)).toStringAsFixed(1)} MB';
    return '${(bytes / (1024 * 1024 * 1024)).toStringAsFixed(1)} GB';
  }

  /// æ‰“å°è¯¦ç»†çš„å…ƒæ•°æ®ä¿¡æ¯
  static void _printMetadataDetails(Map<String, dynamic> metadata) {
    print('ğŸ“Š === æ–‡ä»¶å…ƒæ•°æ®è¯¦ç»†ä¿¡æ¯ ===');
    print('ğŸ“ æ–‡ä»¶å: ${metadata['fileName']}');
    print('ğŸ“‚ æ–‡ä»¶è·¯å¾„: ${metadata['filePath']}');
    print('ğŸ“ æ–‡ä»¶å¤§å°: ${metadata['fileSizeFormatted']} (${metadata['fileSize']} bytes)');
    print('ğŸ“‹ æ–‡ä»¶æ‰©å±•å: ${metadata['fileExtension']}');
    print('ğŸ¯ MIME ç±»å‹: ${metadata['mimeType']}');
    print('ğŸ“… æœ€åä¿®æ”¹: ${metadata['lastModified']}');
    print('ğŸ“… åˆ›å»ºæ—¶é—´: ${metadata['created']}');
    print('ğŸ·ï¸ æ–‡ä»¶ç±»å‹åˆ†ç±»: ${metadata['fileType']}');
    print('ğŸ‘ï¸ æ˜¯å¦å¯è¯»: ${metadata['isReadable']}');
    print('ğŸ“Š === å…ƒæ•°æ®è¯¦ç»†ä¿¡æ¯ç»“æŸ ===');
  }

  /// æ‰“å°å¤„ç†ç»“æœçš„å…ƒæ•°æ®ä¿¡æ¯
  static void _printProcessResultMetadata(Map<String, dynamic>? metadata) {
    if (metadata == null) {
      print('âš ï¸ å¤„ç†ç»“æœå…ƒæ•°æ®ä¸ºç©º');
      return;
    }
    
    print('ğŸ“Š === å¤„ç†ç»“æœå…ƒæ•°æ® ===');
    print('ğŸ“ æ–‡ä»¶å: ${metadata['fileName']}');
    print('ğŸ·ï¸ æ–‡ä»¶ç±»å‹åˆ†ç±»: ${metadata['fileType']}');
    print('ğŸ“„ å†…å®¹ç±»å‹: ${metadata['contentType']}');
    
    // æ ¹æ®å†…å®¹ç±»å‹æ‰“å°ç‰¹å®šä¿¡æ¯
    switch (metadata['contentType']) {
      case 'image':
        print('ğŸ–¼ï¸ å›¾ç‰‡ä¿¡æ¯:');
        print('  - Base64 é•¿åº¦: ${metadata['base64Length']}');
        if (metadata['dimensions'] != null) {
          print('  - å°ºå¯¸: ${metadata['dimensions']}');
        }
        break;
      case 'text':
        print('ğŸ“ æ–‡æœ¬ä¿¡æ¯:');
        print('  - è¡Œæ•°: ${metadata['lineCount']}');
        print('  - å­—æ•°: ${metadata['wordCount']}');
        break;
      case 'code':
        print('ğŸ’» ä»£ç ä¿¡æ¯:');
        print('  - ç¼–ç¨‹è¯­è¨€: ${metadata['language']}');
        print('  - æ€»è¡Œæ•°: ${metadata['lineCount']}');
        if (metadata['codeAnalysis'] != null) {
          final analysis = metadata['codeAnalysis'] as Map<String, dynamic>;
          print('  - ä»£ç åˆ†æ:');
          print('    * æ€»è¡Œæ•°: ${analysis['totalLines']}');
          print('    * éç©ºè¡Œ: ${analysis['nonEmptyLines']}');
          print('    * æ³¨é‡Šè¡Œ: ${analysis['commentLines']}');
          print('    * ä»£ç è¡Œ: ${analysis['codeLines']}');
          print('    * æ³¨é‡Šç‡: ${analysis['commentRatio']}%');
        }
        break;
      case 'csv':
        print('ğŸ“Š CSV ä¿¡æ¯:');
        print('  - è¡Œæ•°: ${metadata['lineCount']}');
        print('  - åˆ—æ•°: ${metadata['columnCount']}');
        if (metadata['headers'] != null) {
          print('  - è¡¨å¤´: ${metadata['headers']}');
        }
        break;
      case 'json':
        print('ğŸ“‹ JSON ä¿¡æ¯:');
        print('  - JSON ç±»å‹: ${metadata['jsonType']}');
        if (metadata['jsonKeys'] != null) {
          print('  - é”®åˆ—è¡¨: ${metadata['jsonKeys']}');
        }
        if (metadata['jsonLength'] != null) {
          print('  - æ•°ç»„é•¿åº¦: ${metadata['jsonLength']}');
        }
        break;
      case 'pdf':
        print('ğŸ“„ PDF æ–‡æ¡£ä¿¡æ¯:');
        print('  - å¤‡æ³¨: ${metadata['note']}');
        break;
      case 'word':
        print('ğŸ“„ Word æ–‡æ¡£ä¿¡æ¯:');
        print('  - æ ¼å¼: ${metadata['wordFormat']}');
        print('  - å¯æå–æ–‡æœ¬: ${metadata['canExtractText']}');
        if (metadata['extractionInfo'] != null) {
          final info = metadata['extractionInfo'] as Map<String, dynamic>;
          print('  - æå–æ–¹æ³•: ${info['extractionMethod']}');
          if (info['textLength'] != null) {
            print('  - æ–‡æœ¬é•¿åº¦: ${info['textLength']} å­—ç¬¦');
          }
          if (info['paragraphCount'] != null) {
            print('  - æ®µè½æ•°: ${info['paragraphCount']}');
          }
          if (info['wordCount'] != null) {
            print('  - å•è¯æ•°: ${info['wordCount']}');
          }
          if (info['error'] != null) {
            print('  - æå–é”™è¯¯: ${info['error']}');
          }
          if (info['note'] != null) {
            print('  - å¤‡æ³¨: ${info['note']}');
          }
        }
        if (metadata['suggestedLibraries'] != null && (metadata['suggestedLibraries'] as List).isNotEmpty) {
          print('  - å»ºè®®åº“: ${metadata['suggestedLibraries']}');
        }
        if (metadata['fileHeader'] != null) {
          print('  - æ–‡ä»¶å¤´éƒ¨: ${metadata['fileHeader']}');
        }
        break;
      case 'archive':
        print('ğŸ“¦ å‹ç¼©æ–‡ä»¶ä¿¡æ¯:');
        print('  - å¤‡æ³¨: ${metadata['note']}');
        break;
      case 'binary':
        print('ğŸ”§ äºŒè¿›åˆ¶æ–‡ä»¶ä¿¡æ¯:');
        print('  - å¤‡æ³¨: ${metadata['note']}');
        break;
    }
    print('ğŸ“Š === å¤„ç†ç»“æœå…ƒæ•°æ®ç»“æŸ ===');
  }
}
